{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Mapping, Iterator\n",
    "import numpy as np\n",
    "import os\n",
    "from problog.logic import Term, Constant\n",
    "from deepproblog.dataset import Dataset\n",
    "from deepproblog.query import Query\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleDataset(Mapping[Term, torch.Tensor]):\n",
    "\n",
    "    def __init__(self, subset: str, puzzle_path: str):\n",
    "        \"\"\"\n",
    "        :param subset: Either 'train' or 'test'.\n",
    "        :param puzzle_path: Path to the directory containing puzzle .npy files.\n",
    "        :param label_path: Path to the directory containing label .npy files.\n",
    "        \"\"\"\n",
    "        self.subset = subset\n",
    "        self.puzzle_files = sorted(\n",
    "            [f for f in os.listdir(puzzle_path) if f.endswith('.npy')]\n",
    "        )\n",
    "        self.puzzles = []\n",
    "        for filename in self.puzzle_files:\n",
    "            puzzle = np.load(os.path.join(puzzle_path, filename), allow_pickle=True)\n",
    "            for i in range(len(puzzle)):\n",
    "                for j in range(len(puzzle[i])):\n",
    "                    if puzzle[i][j] is None:\n",
    "                        puzzle[i][j] = np.zeros((28, 28), dtype=np.float32) / 255.0  # Create normalized zeros\n",
    "                    else:\n",
    "                        puzzle[i][j] = puzzle[i][j].astype(np.float32) / 255.0  # Normalize existing values\n",
    "            self.puzzles.append(puzzle)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.puzzles)\n",
    "\n",
    "    def __iter__(self) -> Iterator:\n",
    "        for i in range(len(self)):\n",
    "            yield self.puzzles[i]\n",
    "\n",
    "    def __getitem__(self, item): #-> torch.Tensor:\n",
    "        return torch.tensor(self.puzzles[int(item[0])][0][0]).unsqueeze(0)\n",
    "        # return torch.from_numpy(self.puzzles[item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0::addition(tensor(test(0)),tensor(test(1)),5), {})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AdditionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, subset: str, labels_path: str):\n",
    "        self.subset = subset\n",
    "        self.label_files = sorted(\n",
    "            [f for f in os.listdir(labels_path) if f.endswith('.npy')]\n",
    "        )\n",
    "        self.labels = []\n",
    "        for filename in self.label_files:\n",
    "            label = np.load(os.path.join(labels_path, filename), allow_pickle=True)\n",
    "            for i in range(len(label)):\n",
    "                for j in range(len(label[i])):\n",
    "                    if label[i][j] is None:\n",
    "                        label[i][j] = 0\n",
    "            # label = label.astype(np.uint8)\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels) // 2\n",
    "\n",
    "    def to_query(self, i: int) -> Query:\n",
    "        image1_id = i*2\n",
    "        image2_id = i*2+1\n",
    "        image1_label = self.labels[image1_id].flatten()[0]\n",
    "        image2_label = self.labels[image2_id].flatten()[0]\n",
    "        image1 = Term(\"tensor\", Term(self.subset, Constant(image1_id)))\n",
    "        image2 = Term(\"tensor\", Term(self.subset, Constant(image2_id)))\n",
    "        label = Constant(int(image1_label) + int(image2_label))\n",
    "        term = Term('addition', image1, image2, label)\n",
    "        return Query(term)\n",
    "\n",
    "ym = AdditionDataset('test', '../mnist_sudoku_generator/dataset/arrays/puzzles/test')\n",
    "ym.to_query(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),\n",
    "            nn.MaxPool2d(2, 2),  # 6 24 24 -> 6 12 12\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(6, 16, 5),  # 6 12 12 -> 16 8 8\n",
    "            nn.MaxPool2d(2, 2),  # 16 8 8 -> 16 4 4\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16 * 4 * 4, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Softmax(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset size: 2000\n"
     ]
    }
   ],
   "source": [
    "data_path = '../mnist_sudoku_generator/dataset/images/puzzles/'\n",
    "labels_path = '../mnist_sudoku_generator/dataset/arrays/puzzles/'\n",
    "\n",
    "# train_dataset = PuzzleLabelDataset('train', data_path+'train', labels_path+'train')\n",
    "test_dataset = PuzzleDataset('test', data_path+'test')\n",
    "# print('train dataset size:', len(train_dataset))\n",
    "print('test dataset size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdditionDataset('test', '../mnist_sudoku_generator/dataset/arrays/puzzles/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from deepproblog.dataset import DataLoader\n",
    "from deepproblog.engines import ExactEngine\n",
    "from deepproblog.model import Model\n",
    "from deepproblog.network import Network\n",
    "from deepproblog.train import train_model\n",
    "\n",
    "network = MNIST_Net()\n",
    "net = Network(network, \"mnist_net\", batching=True)\n",
    "net.optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "\n",
    "model = Model(\"addition.pl\", [net])\n",
    "model.set_engine(ExactEngine(model))\n",
    "train = PuzzleDataset(\"train\", \"../mnist_sudoku_generator/dataset/images/puzzles/train\")\n",
    "test = PuzzleDataset(\"test\", \"../mnist_sudoku_generator/dataset/images/puzzles/test\")\n",
    "model.add_tensor_source(\"train\", train)\n",
    "model.add_tensor_source(\"test\", test)\n",
    "\n",
    "dataset = AdditionDataset('train', '../mnist_sudoku_generator/dataset/arrays/puzzles/train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  for 1 epoch(s)\n",
      "Epoch 1\n",
      "Iteration:  100 \ts:5.2542 \tAverage Loss:  2.5576387731311843\n",
      "Iteration:  200 \ts:5.3462 \tAverage Loss:  1.7119511892792798\n",
      "Iteration:  300 \ts:5.4724 \tAverage Loss:  1.725659420330803\n",
      "Iteration:  400 \ts:4.9586 \tAverage Loss:  1.7328504049865114\n",
      "Iteration:  500 \ts:5.2718 \tAverage Loss:  1.6452261650564948\n",
      "Iteration:  600 \ts:5.0650 \tAverage Loss:  1.76128124415986\n",
      "Iteration:  700 \ts:5.3677 \tAverage Loss:  1.8094900826937186\n",
      "Iteration:  800 \ts:5.0815 \tAverage Loss:  1.6175137523793273\n",
      "Iteration:  900 \ts:5.3438 \tAverage Loss:  1.239225293014506\n",
      "Iteration:  1000 \ts:4.9532 \tAverage Loss:  1.017424865022666\n",
      "Iteration:  1100 \ts:5.3754 \tAverage Loss:  0.9075649040276267\n",
      "Iteration:  1200 \ts:5.3588 \tAverage Loss:  0.7864382118938056\n",
      "Iteration:  1300 \ts:5.0832 \tAverage Loss:  0.7062576016010348\n",
      "Iteration:  1400 \ts:5.3315 \tAverage Loss:  0.4756318800499355\n",
      "Iteration:  1500 \ts:5.0766 \tAverage Loss:  0.5739850180163603\n",
      "Iteration:  1600 \ts:5.4363 \tAverage Loss:  0.39399101781215223\n",
      "Iteration:  1700 \ts:4.8327 \tAverage Loss:  0.40085798035984055\n",
      "Iteration:  1800 \ts:5.3790 \tAverage Loss:  0.37312448129666737\n",
      "Iteration:  1900 \ts:4.9340 \tAverage Loss:  0.3328537924967645\n",
      "Iteration:  2000 \ts:5.3173 \tAverage Loss:  0.23333381569963357\n",
      "Epoch time:  104.29389238357544\n",
      "{addition(tensor(train(0)),tensor(train(1)),6): tensor(0.9986, grad_fn=<SelectBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "loader = DataLoader(dataset, 2, False)\n",
    "train_model(model, loader, 1, log_iter=100, profile=0)\n",
    "model.save_state(\"snapshot/trained_model.pth\")\n",
    "\n",
    "# Query the model\n",
    "query = dataset.to_query(0)\n",
    "result = model.solve([query])[0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepproblog.evaluate import get_confusion_matrix\n",
    "dataset_test = AdditionDataset('test', '../mnist_sudoku_generator/dataset/arrays/puzzles/test')\n",
    "cm = get_confusion_matrix(model, dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.933)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         \t  \t  \t  \t  \t   \t  \t  \t  \tActual\t  \t  \t  \t  \t  \t  \t  \t  \n",
      "         \t  \t 5\t 6\t 1\t  0\t 4\t 2\t 7\t    11\t10\t13\t 8\t 9\t 3\t14\t12\t15\n",
      "         \t 5\t94\t 0\t 0\t  0\t 0\t 0\t 0\t     0\t 2\t 0\t 1\t 1\t 2\t 0\t 0\t 0\n",
      "         \t 6\t 1\t81\t 0\t  0\t 4\t 0\t 1\t     2\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\n",
      "         \t 1\t 1\t 1\t53\t  0\t 0\t 0\t 3\t     0\t 0\t 0\t 2\t 0\t 0\t 0\t 0\t 0\n",
      "         \t 0\t 0\t 0\t 0\t239\t 0\t 0\t 0\t     0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\n",
      "         \t 4\t 0\t 0\t 0\t  0\t63\t 1\t 1\t     1\t 0\t 0\t 0\t 6\t 0\t 0\t 0\t 0\n",
      "         \t 2\t 0\t 1\t 0\t  0\t 0\t66\t 2\t     0\t 0\t 0\t 1\t 0\t 2\t 0\t 0\t 0\n",
      "         \t 7\t 1\t 0\t 0\t  0\t 0\t 1\t65\t     0\t 0\t 0\t 2\t 2\t 0\t 0\t 0\t 0\n",
      "Predicted\t11\t 0\t 0\t 0\t  0\t 0\t 0\t 0\t    23\t 0\t 1\t 0\t 0\t 0\t 0\t 0\t 0\n",
      "         \t10\t 0\t 0\t 0\t  0\t 0\t 0\t 0\t     2\t38\t 0\t 0\t 0\t 0\t 0\t 1\t 0\n",
      "         \t13\t 0\t 0\t 0\t  0\t 0\t 0\t 0\t     2\t 0\t11\t 0\t 0\t 0\t 0\t 0\t 0\n",
      "         \t 8\t 0\t 0\t 0\t  0\t 0\t 1\t 0\t     0\t 0\t 2\t54\t 2\t 0\t 2\t 0\t 1\n",
      "         \t 9\t 0\t 0\t 0\t  0\t 1\t 0\t 0\t     0\t 2\t 0\t 0\t30\t 1\t 0\t 0\t 0\n",
      "         \t 3\t 2\t 0\t 0\t  0\t 0\t 0\t 1\t     0\t 1\t 0\t 1\t 0\t84\t 0\t 0\t 0\n",
      "         \t14\t 0\t 0\t 0\t  0\t 0\t 0\t 0\t     0\t 0\t 0\t 0\t 0\t 0\t 8\t 0\t 0\n",
      "         \t12\t 0\t 0\t 0\t  0\t 0\t 0\t 1\t     0\t 0\t 0\t 0\t 1\t 0\t 0\t18\t 0\n",
      "         \t15\t 0\t 0\t 0\t  0\t 0\t 0\t 0\t     0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 6\n"
     ]
    }
   ],
   "source": [
    "print(str(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APf6xfFPijT/AAfop1bUxMbZZUiPkoGYFjjOMjgdT9O9bEciTRJLGwZHUMpHcHpTqK8s+P1zBH8OfsrzRrPcXcQijLAM+Dk4Ht3r0uwhe3061gkADxwojY9QADViivNPjJounXui6Zf3NpHLdRahbwJI2ciN5F3L6c4H+TXpdFFQ3NpbXsBgu7eKeEsrGOVAy5UhgcHuCAR6ECpqK//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAeElEQVR4AWP8z4AbMOGWYmCgi+QB9nYUN/xHBm1MvCeQ+OgO+nYdSSu6JJIUnbyCYiOmnVyaSApQXXucgc8cSZIByc+/ApkYpJD4/5El5zEzM0kjSyIba6Pvy+CNbCqypOpZMwZdXJLI4mA2ss6BkSxGtZaRNokaAOKxUpO1DIsCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APf64/Wvil4N8PavJpep6ysN3EP3iLBJIEPBAJVSM4PSovCXxQ0Txpq8+n6VaaniIMRcy24WFwpxkMGJHUHDAHmu1or5w+PPhKDRPEFl4stkjeK9mC3MEhLb5V5z/ulRgj296988Oz2N14b0640yGGGymt0khihUBEUqDgAenStOivm34reOrH4kvpPhzwva3V5OLgyb/LK7m2kbQvXpkk9sV9AeH9ObSPDmmac4jElraxQv5f3dyqAce2Qa0qKzrTw/othfPfWekWFvduMNPDbIkjD3YDJrRor/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5klEQVR4AWP8z4AbMOGWYmCgh+R+oANOMzIxBZ2FuuQ/HGSys7Czs7MxAcF0iCADXG4hM0gYCIQL635BRFngXvkN9fFiLwGYGLpX0p8EweUYEMZ+2sAPNLMfbg2QgZD8/18DKKnxHEkWWXKtAJpWZDuD2oAueQVzDZBGlmSQAgqsf4OQRZEECd86hkeSWwCPpKYdHkmEFJqD3iPLgNhIft4jDPSnC5IAIyyBbX96b8ZHBgalfbJI2mEKRYC6mJh4OmF8EA03FizJcgxZDiHZE8jEpLUMRe4/3E4km+BMjOCDywAZeCUB64fXXEiJXGIAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(test[[2]].numpy().reshape(28, 28) * 255).show()\n",
    "Image.fromarray(test[[3]].numpy().reshape(28, 28) * 255).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.8588,\n",
      "          -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,  0.3020,\n",
      "           1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843,  0.7647,  0.3490,  0.9843,\n",
      "           0.8980,  0.5294, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569, -0.3569,\n",
      "          -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.8588,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
      "           0.5529,  0.4275,  0.9373,  0.8902, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,  0.9843,  0.6078,\n",
      "          -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.4902,\n",
      "          -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843,\n",
      "          -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.8902,\n",
      "           0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,\n",
      "           0.8824,  0.9843,  0.9843, -0.0667, -0.8039, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.8745, -0.2706,  0.9765,  0.9843,  0.4667, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529, -0.4980,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.6392,  0.0196,  0.4353,  0.9843,  0.9843,  0.6235, -0.9843,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.1608,\n",
      "           0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.5765, -0.3882, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,  0.9843,  0.9843,\n",
      "           0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
      "           0.3412,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294,\n",
      "          -0.3725, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.5686,  0.3490,  0.7725,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843,  0.9137,  0.0431, -0.9137,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,\n",
      "           0.9843,  0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Mapping, Iterator\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from problog.logic import Term, Constant\n",
    "\n",
    "from deepproblog.dataset import Dataset\n",
    "from deepproblog.query import Query\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "datasets = {\n",
    "    \"train\": torchvision.datasets.MNIST(\n",
    "        root='data/', train=True, download=True, transform=transform\n",
    "    ),\n",
    "    \"test\": torchvision.datasets.MNIST(\n",
    "        root='data/', train=False, download=True, transform=transform\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "class MNISTImages(Mapping[Term, torch.Tensor]):\n",
    "\n",
    "    def __iter__(self) -> Iterator:\n",
    "        for i in range(self.dataset):\n",
    "            yield self.dataset[i][0]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "        self.dataset = datasets[self.subset]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        print(self.dataset[int(item[0])][0])\n",
    "        return self.dataset[int(item[0])][0]\n",
    "\n",
    "\n",
    "class AdditionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "        self.dataset = datasets[subset]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // 2\n",
    "\n",
    "    def to_query(self, i: int) -> Query:\n",
    "        image1 = Term(\"tensor\", Term(self.subset, Constant(i * 2)))\n",
    "        image2 = Term(\"tensor\", Term(self.subset, Constant(i * 2 + 1)))\n",
    "        label = Constant(int(self.dataset[i*2][1] + self.dataset[i*2+1][1]))\n",
    "        term = Term('addition', image1, image2, label)\n",
    "        return Query(term)\n",
    "\n",
    "ym = MNISTImages('train')\n",
    "ym[[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prolog-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
